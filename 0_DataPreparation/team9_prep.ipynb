{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daten einlesen und Pipeline definieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id      Datum  Warengruppe      Umsatz  Bewoelkung  Temperatur  \\\n",
      "0  1307011 2013-07-01            1  148.828353         6.0     17.8375   \n",
      "1  1307021 2013-07-02            1  159.793757         3.0     17.3125   \n",
      "2  1307031 2013-07-03            1  111.885594         7.0     21.0750   \n",
      "3  1307041 2013-07-04            1  168.864941         7.0     18.8500   \n",
      "4  1307051 2013-07-05            1  171.280754         5.0     19.9750   \n",
      "\n",
      "   Windgeschwindigkeit Wettercode  KielerWoche  feiertag  ...  SL  SN  ST  SH  \\\n",
      "0                 15.0       20.0          NaN         0  ...   0   0   0   1   \n",
      "1                 10.0        nan          NaN         0  ...   0   0   0   1   \n",
      "2                  6.0       61.0          NaN         0  ...   0   0   0   1   \n",
      "3                  7.0       20.0          NaN         0  ...   0   0   0   1   \n",
      "4                 12.0        nan          NaN         0  ...   0   0   0   1   \n",
      "\n",
      "   TH  VPI_brot_getreide  VPI_molkerei_ei  VPI_speiseoel_fett  VPI_Obst  \\\n",
      "0   0               92.4             88.6                88.6      86.1   \n",
      "1   0               92.4             88.6                88.6      86.1   \n",
      "2   0               92.4             88.6                88.6      86.1   \n",
      "3   0               92.4             88.6                88.6      86.1   \n",
      "4   0               92.4             88.6                88.6      86.1   \n",
      "\n",
      "   VPI_zucker_suesses  \n",
      "0                94.9  \n",
      "1                94.9  \n",
      "2                94.9  \n",
      "3                94.9  \n",
      "4                94.9  \n",
      "\n",
      "[5 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# 1. Daten einlesen und zusammenführen\n",
    "df1 = pd.read_csv('../umsatzdaten_gekuerzt.csv')\n",
    "df2 = pd.read_csv('../wetter.csv')\n",
    "df3 = pd.read_csv('../kiwo.csv')\n",
    "df4 = pd.read_csv('../Feier_Bruecke_Ferien_bis2018.csv')\n",
    "df5 = pd.read_csv('../VPI.csv')\n",
    "\n",
    "df = df1.merge(df2, on='Datum', how='left')\n",
    "df = df.merge(df3, on='Datum', how='left')\n",
    "df = df.merge(df4, on='Datum', how='left')\n",
    "df = df.merge(df5, on='Datum', how='left')\n",
    "\n",
    "# Sicherstellen, dass 'Datum' als datetime konvertiert ist\n",
    "df['Datum'] = pd.to_datetime(df['Datum'])\n",
    "df.sort_values(by='Datum')\n",
    "\n",
    "\n",
    "# 2. Pipeline-Komponenten definieren\n",
    "\n",
    "# a) Feature Engineering: Erstellen von Datum- und zyklischen Features\n",
    "def add_features(df):\n",
    "    df = df.copy()\n",
    "    # Basismerkmale\n",
    "    df['Jahr'] = df['Datum'].dt.year\n",
    "    df['Monat'] = df['Datum'].dt.month\n",
    "    df['Wochentag'] = df['Datum'].dt.weekday\n",
    "    df['Kalenderwoche'] = df['Datum'].dt.isocalendar().week\n",
    "    df['Tag_im_Jahr'] = df['Datum'].dt.dayofyear\n",
    "    df['Ist_Wochenende'] = df['Wochentag'].isin([5, 6]).astype(int)\n",
    "    \n",
    "    # Zyklische Merkmale\n",
    "    df['Tag_im_Jahr_sin'] = np.sin(2 * np.pi * df['Tag_im_Jahr'] / 365)\n",
    "    df['Tag_im_Jahr_cos'] = np.cos(2 * np.pi * df['Tag_im_Jahr'] / 365)\n",
    "    df['Monat_sin'] = np.sin(2 * np.pi * df['Monat'] / 12)\n",
    "    df['Monat_cos'] = np.cos(2 * np.pi * df['Monat'] / 12)\n",
    "    df['Wochentag_sin'] = np.sin(2 * np.pi * df['Wochentag'] / 7)\n",
    "    df['Wochentag_cos'] = np.cos(2 * np.pi * df['Wochentag'] / 7)\n",
    "    \n",
    "    # Entfernen der 'Datum'-Spalte nach der Feature-Erstellung\n",
    "    df = df.drop('Datum', axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# b) FunctionTransformer für Feature Engineering\n",
    "feature_engineering = FunctionTransformer(add_features, validate=False)\n",
    "\n",
    "# c) Definieren der Feature-Gruppen\n",
    "numeric_features = ['Temperatur', 'Bewoelkung', 'Windgeschwindigkeit',\n",
    "                    'Tag_im_Jahr_sin', 'Tag_im_Jahr_cos',\n",
    "                    'Monat_sin', 'Monat_cos',\n",
    "                    'Wochentag_sin', 'Wochentag_cos', 'KielerWoche'\n",
    "                    'feiertag', 'brueckentag', 'BW', 'BY', 'B', \n",
    "                    'BB', 'HB', 'HH', 'HE', 'MV', 'NI', 'NW', 'RP', \n",
    "                    'SL', 'SN', 'ST', 'SH', 'TH', 'VPI_brot_getreide']\n",
    "                    \n",
    "categorical_features = ['Warengruppe', 'Wettercode', 'Wochentag']\n",
    "\n",
    "# d) Definieren des ColumnTransformers\n",
    "# Stellen Sie sicher, dass 'Wettercode' als String vorliegt\n",
    "df['Wettercode'] = df['Wettercode'].astype(str)\n",
    "\n",
    "# Liste der Kategorien für 'Wettercode'\n",
    "wettercode_categories = [str(i) for i in range(0, 100)] + ['Unbekannt']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), numeric_features),\n",
    "        \n",
    "        ('wettercode', OneHotEncoder(categories=[wettercode_categories], handle_unknown='ignore'), ['Wettercode']),\n",
    "        \n",
    "        ('warengruppe', OneHotEncoder(handle_unknown='ignore'), ['Warengruppe']),\n",
    "        \n",
    "        ('wochentag', OneHotEncoder(handle_unknown='ignore'), ['Wochentag'])\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Define your date thresholds\n",
    "train_end_date = '2017-07-31'\n",
    "validation_end_date = '2018-08-31'\n",
    "# Convert to datetime if not already\n",
    "\n",
    "# Split the data based on the date thresholds\n",
    "\n",
    "train_data = df[df['Datum'] <= train_end_date]\n",
    "test_data = df[df['Datum'] > train_end_date]\n",
    "\n",
    "\n",
    "X_train  = train_data.drop(['Umsatz'], axis=1)  # Behalten Sie 'Datum' in X für die Pipeline\n",
    "y_train = train_data['Umsatz']\n",
    "\n",
    "X_test  = test_data.drop(['Umsatz'], axis=1)  # Behalten Sie 'Datum' in X für die Pipeline\n",
    "y_test = test_data['Umsatz']\n",
    "\n",
    "\n",
    "\n",
    "#erste fünf Zeilen anzeigen\n",
    "print(df.head())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
