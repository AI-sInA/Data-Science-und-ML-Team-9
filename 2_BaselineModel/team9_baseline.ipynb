{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daten einlesen und Pipeline definieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# 1. Daten einlesen und zusammenführen\n",
    "df1 = pd.read_csv('../umsatzdaten_gekuerzt.csv')\n",
    "df2 = pd.read_csv('../wetter.csv')\n",
    "df3 = pd.read_csv('../kiwo.csv')\n",
    "df4 = pd.read_csv('../Feier_Bruecke_Ferien_bis2018.csv')\n",
    "\n",
    "df = df1.merge(df2, on='Datum', how='left')\n",
    "df = df.merge(df3, on='Datum', how='left')\n",
    "df = df.merge(df4, on='Datum', how='left')\n",
    "\n",
    "# replace NaN with False for 'KielerWoche'\n",
    "df['KielerWoche'] = df['KielerWoche'].fillna(False)\n",
    "df['KielerWoche'] = df['KielerWoche'].astype('bool')\n",
    "\n",
    "# Sicherstellen, dass 'Datum' als datetime konvertiert ist\n",
    "df['Datum'] = pd.to_datetime(df['Datum'])\n",
    "\n",
    "# 2. Pipeline-Komponenten definieren\n",
    "\n",
    "# a) Feature Engineering: Erstellen von Datum- und zyklischen Features\n",
    "def add_features(df):\n",
    "    # df = df.copy()\n",
    "    # Basismerkmale\n",
    "    df['Jahr'] = df['Datum'].dt.year\n",
    "    df['Monat'] = df['Datum'].dt.month\n",
    "    df['Wochentag'] = df['Datum'].dt.weekday\n",
    "    df['Kalenderwoche'] = df['Datum'].dt.isocalendar().week\n",
    "    df['Tag_im_Jahr'] = df['Datum'].dt.dayofyear\n",
    "    df['Ist_Wochenende'] = df['Wochentag'].isin([5, 6]).astype(int)\n",
    "    \n",
    "    # Zyklische Merkmale\n",
    "    df['Tag_im_Jahr_sin'] = np.sin(2 * np.pi * df['Tag_im_Jahr'] / 365)\n",
    "    df['Tag_im_Jahr_cos'] = np.cos(2 * np.pi * df['Tag_im_Jahr'] / 365)\n",
    "    df['Monat_sin'] = np.sin(2 * np.pi * df['Monat'] / 12)\n",
    "    df['Monat_cos'] = np.cos(2 * np.pi * df['Monat'] / 12)\n",
    "    df['Wochentag_sin'] = np.sin(2 * np.pi * df['Wochentag'] / 7)\n",
    "    df['Wochentag_cos'] = np.cos(2 * np.pi * df['Wochentag'] / 7)\n",
    "        \n",
    "    return df\n",
    "\n",
    "df = add_features(df)\n",
    "# b) FunctionTransformer für Feature Engineering\n",
    "feature_engineering = FunctionTransformer(add_features, validate=False)\n",
    "\n",
    "# c) Definieren der Feature-Gruppen\n",
    "numeric_features = ['Temperatur', 'Bewoelkung', 'Windgeschwindigkeit',\n",
    "                    'Tag_im_Jahr_sin', 'Tag_im_Jahr_cos',\n",
    "                    'Monat_sin', 'Monat_cos',\n",
    "                    'Wochentag_sin', 'Wochentag_cos','feiertag', 'KielerWoche',\n",
    "                    'brueckentag', 'BW', 'BY', 'B', 'BB', 'HB', 'HH', 'HE', 'MV',\n",
    "                      'NI', 'NW', 'RP', 'SL', 'SN', 'ST', 'SH', 'TH']\n",
    "                    \n",
    "categorical_features = ['Warengruppe', 'Wettercode', 'Wochentag']\n",
    "\n",
    "# d) Definieren des ColumnTransformers\n",
    "# Stellen Sie sicher, dass 'Wettercode' als String vorliegt\n",
    "df['Wettercode'] = df['Wettercode'].astype(str)\n",
    "\n",
    "# Liste der Kategorien für 'Wettercode'\n",
    "wettercode_categories = [str(i) for i in range(0, 100)] + ['Unbekannt']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), numeric_features),\n",
    "        \n",
    "        ('wettercode', OneHotEncoder(categories=[wettercode_categories], handle_unknown='ignore'), ['Wettercode']),\n",
    "        \n",
    "        ('warengruppe', OneHotEncoder(handle_unknown='ignore'), ['Warengruppe']),\n",
    "        \n",
    "        ('wochentag', OneHotEncoder(handle_unknown='ignore'), ['Wochentag'])\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# Define your date thresholds\n",
    "train_end_date = '2017-07-31'\n",
    "validation_end_date = '2018-07-31'\n",
    "\n",
    "train_data = df[df['Datum'] <= train_end_date]\n",
    "test_data = df[df['Datum'] > train_end_date]\n",
    "\n",
    "df = df.drop('Datum', axis=1)\n",
    "\n",
    "X = df.drop(['Umsatz'], axis=1)\n",
    "y = df['Umsatz']\n",
    "\n",
    "X_train  = train_data.drop(['Umsatz'], axis=1)  # Behalten Sie 'Datum' in X für die Pipeline\n",
    "y_train = train_data['Umsatz']\n",
    "\n",
    "X_test  = test_data.drop(['Umsatz'], axis=1)  # Behalten Sie 'Datum' in X für die Pipeline\n",
    "y_test = test_data['Umsatz']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of            id  Warengruppe      Umsatz  Bewoelkung  Temperatur  \\\n",
       "0     1307011            1  148.828353         6.0     17.8375   \n",
       "1     1307021            1  159.793757         3.0     17.3125   \n",
       "2     1307031            1  111.885594         7.0     21.0750   \n",
       "3     1307041            1  168.864941         7.0     18.8500   \n",
       "4     1307051            1  171.280754         5.0     19.9750   \n",
       "...       ...          ...         ...         ...         ...   \n",
       "9329  1712216            6   87.471228         7.0      6.2375   \n",
       "9330  1712226            6   71.911652         7.0      5.7625   \n",
       "9331  1712236            6   84.062223         7.0      7.8000   \n",
       "9332  1712246            6   60.981969         7.0      8.1125   \n",
       "9333  1712276            6   34.972644         7.0      4.6125   \n",
       "\n",
       "      Windgeschwindigkeit Wettercode  KielerWoche  feiertag  brueckentag  ...  \\\n",
       "0                    15.0       20.0        False         0            0  ...   \n",
       "1                    10.0        nan        False         0            0  ...   \n",
       "2                     6.0       61.0        False         0            0  ...   \n",
       "3                     7.0       20.0        False         0            0  ...   \n",
       "4                    12.0        nan        False         0            0  ...   \n",
       "...                   ...        ...          ...       ...          ...  ...   \n",
       "9329                 10.0       21.0        False         0            0  ...   \n",
       "9330                  9.0       10.0        False         0            0  ...   \n",
       "9331                 19.0       61.0        False         0            0  ...   \n",
       "9332                 16.0       61.0        False         0            0  ...   \n",
       "9333                  7.0       21.0        False         0            0  ...   \n",
       "\n",
       "      Wochentag  Kalenderwoche  Tag_im_Jahr  Ist_Wochenende  Tag_im_Jahr_sin  \\\n",
       "0             0             27          182               0         0.008607   \n",
       "1             1             27          183               0        -0.008607   \n",
       "2             2             27          184               0        -0.025818   \n",
       "3             3             27          185               0        -0.043022   \n",
       "4             4             27          186               0        -0.060213   \n",
       "...         ...            ...          ...             ...              ...   \n",
       "9329          3             51          355               0        -0.171293   \n",
       "9330          4             51          356               0        -0.154309   \n",
       "9331          5             51          357               1        -0.137279   \n",
       "9332          6             51          358               1        -0.120208   \n",
       "9333          2             52          361               0        -0.068802   \n",
       "\n",
       "      Tag_im_Jahr_cos     Monat_sin  Monat_cos  Wochentag_sin  Wochentag_cos  \n",
       "0           -0.999963 -5.000000e-01  -0.866025       0.000000       1.000000  \n",
       "1           -0.999963 -5.000000e-01  -0.866025       0.781831       0.623490  \n",
       "2           -0.999667 -5.000000e-01  -0.866025       0.974928      -0.222521  \n",
       "3           -0.999074 -5.000000e-01  -0.866025       0.433884      -0.900969  \n",
       "4           -0.998186 -5.000000e-01  -0.866025      -0.433884      -0.900969  \n",
       "...               ...           ...        ...            ...            ...  \n",
       "9329         0.985220 -2.449294e-16   1.000000       0.433884      -0.900969  \n",
       "9330         0.988023 -2.449294e-16   1.000000      -0.433884      -0.900969  \n",
       "9331         0.990532 -2.449294e-16   1.000000      -0.974928      -0.222521  \n",
       "9332         0.992749 -2.449294e-16   1.000000      -0.781831       0.623490  \n",
       "9333         0.997630 -2.449294e-16   1.000000       0.974928      -0.222521  \n",
       "\n",
       "[9334 rows x 38 columns]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² on test: 0.7360924544022935\n",
      "adjusted R² on test: 0.7350705471589336\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "pipeline_1 = Pipeline(steps=[\n",
    "    ('feature_engineering', feature_engineering),\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('model',  LinearRegression())\n",
    "])\n",
    "pipeline_1.fit(X_train, y_train)\n",
    "\n",
    "lr_y_pred = pipeline_1.predict(X_test)\n",
    "\n",
    "def r2(actual: np.ndarray, predicted: np.ndarray):\n",
    "    \"\"\" R2 Score \"\"\"\n",
    "    return r2_score(actual, predicted)\n",
    "def adjr2(actual: np.ndarray, predicted: np.ndarray, rowcount: int, featurecount: int):\n",
    "    \"\"\" R2 Score \"\"\"\n",
    "    return 1-(1-r2(actual,predicted))*(rowcount-1)/(rowcount-featurecount)\n",
    "\n",
    "\n",
    "\n",
    "print(\"R² on test:\", r2_score(y_test, lr_y_pred))\n",
    "print(\"adjusted R² on test:\", adjr2(y_test, lr_y_pred, len(df), df.drop(['Umsatz'], axis=1) .shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestRegressor\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split, GridSearchCV\n\u001b[0;32m----> 4\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m \u001b[43mPipeline\u001b[49m(steps\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m      5\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_engineering\u001b[39m\u001b[38;5;124m'\u001b[39m, feature_engineering),\n\u001b[1;32m      6\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreprocessing\u001b[39m\u001b[38;5;124m'\u001b[39m, preprocessor),\n\u001b[1;32m      7\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m, RandomForestRegressor(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m))\n\u001b[1;32m      8\u001b[0m ])\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# 4. Modell trainieren\u001b[39;00m\n\u001b[1;32m     11\u001b[0m pipeline\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('feature_engineering', feature_engineering),\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('model', RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "# 4. Modell trainieren\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 5. Vorhersagen treffen und evaluieren\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(\"R² on test:\", r2_score(y_test, y_pred))\n",
    "print(\"adjusted R² on test:\", adjr2(y_test, lr_y_pred, len(y), X.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 6. Hyperparameter-Tuning (optional)\n",
    "param_grid = {\n",
    "    'model__n_estimators': [100, 200, 500],\n",
    "    'model__max_depth': [None, 10, 20, 50],\n",
    "    'model__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=3, scoring='r2', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best RF Params:\", grid_search.best_params_)\n",
    "y_pred_best = grid_search.predict(X_test)\n",
    "print(\"Test R² Best RF:\", r2_score(y_test, y_pred_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance evaluieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred_best' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Scatterplot\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m plt\u001b[38;5;241m.\u001b[39mscatter(y_test, \u001b[43my_pred_best\u001b[49m, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot([y_test\u001b[38;5;241m.\u001b[39mmin(), y_test\u001b[38;5;241m.\u001b[39mmax()], [y_test\u001b[38;5;241m.\u001b[39mmin(), y_test\u001b[38;5;241m.\u001b[39mmax()], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr--\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Diagonale Linie\u001b[39;00m\n\u001b[1;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTatsächliche Werte\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_pred_best' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Scatterplot\n",
    "plt.scatter(y_test, y_pred_best, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')  # Diagonale Linie\n",
    "plt.xlabel(\"Tatsächliche Werte\")\n",
    "plt.ylabel(\"Vorhergesagte Werte\")\n",
    "plt.title(\"Tatsächliche Werte vs. Vorhergesagte Werte\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "residuals = y_test - y_pred_best\n",
    "\n",
    "# Residualplot\n",
    "plt.scatter(y_pred_best, residuals, alpha=0.5, color='g')\n",
    "plt.axhline(0, color='r', linestyle='--')\n",
    "plt.xlabel(\"Vorhergesagte Werte\")\n",
    "plt.ylabel(\"Residuen\")\n",
    "plt.title(\"Residualplot\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Histogramm der Residuen\n",
    "sns.histplot(residuals, kde=True, color='y')\n",
    "plt.axvline(0, color='r', linestyle='--')\n",
    "plt.xlabel(\"Residuen\")\n",
    "plt.title(\"Verteilung der Residuen\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(y_test.values, label=\"Tatsächliche Werte\")\n",
    "plt.plot(y_pred_best, label=\"Vorhergesagte Werte\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Umsatz\")\n",
    "plt.title(\"Vergleich der tatsächlichen und vorhergesagten Werte\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuronales Netz nutzen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">142</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">568</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,430</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">44</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m142\u001b[0m)            │           \u001b[38;5;34m568\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,430\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │            \u001b[38;5;34m44\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m5\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,047</span> (8.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,047\u001b[0m (8.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,763</span> (6.89 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,763\u001b[0m (6.89 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">284</span> (1.11 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m284\u001b[0m (1.11 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 63436.3789 - mae: 199.4451 - val_loss: 14798.2979 - val_mae: 89.2149\n",
      "Epoch 2/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790us/step - loss: 18279.1035 - mae: 98.2983 - val_loss: 10409.1436 - val_mae: 78.3527\n",
      "Epoch 3/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step - loss: 13045.4727 - mae: 82.4085 - val_loss: 6973.2705 - val_mae: 60.5138\n",
      "Epoch 4/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step - loss: 10467.5117 - mae: 68.2818 - val_loss: 4671.5322 - val_mae: 48.1739\n",
      "Epoch 5/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781us/step - loss: 7313.5576 - mae: 55.9213 - val_loss: 4456.9141 - val_mae: 48.9878\n",
      "Epoch 6/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - loss: 5852.0503 - mae: 54.4616 - val_loss: 4521.5488 - val_mae: 49.0784\n",
      "Epoch 7/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 6356.3535 - mae: 53.5859 - val_loss: 4423.3003 - val_mae: 47.8799\n",
      "Epoch 8/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - loss: 6676.5059 - mae: 52.3929 - val_loss: 4184.7412 - val_mae: 46.0835\n",
      "Epoch 9/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791us/step - loss: 6031.4199 - mae: 50.1656 - val_loss: 4320.9482 - val_mae: 46.7493\n",
      "Epoch 10/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - loss: 5097.3647 - mae: 49.3645 - val_loss: 3885.3513 - val_mae: 43.5093\n",
      "Epoch 11/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5364.7568 - mae: 50.1202 - val_loss: 3799.5913 - val_mae: 42.7624\n",
      "Epoch 12/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766us/step - loss: 5381.9985 - mae: 48.0314 - val_loss: 4053.5437 - val_mae: 44.3522\n",
      "Epoch 13/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 754us/step - loss: 5081.3687 - mae: 47.8059 - val_loss: 3963.3831 - val_mae: 43.8292\n",
      "Epoch 14/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760us/step - loss: 4826.1084 - mae: 46.9641 - val_loss: 4423.8955 - val_mae: 47.1516\n",
      "Epoch 15/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753us/step - loss: 7763.4175 - mae: 50.2248 - val_loss: 4038.7695 - val_mae: 44.2474\n",
      "Epoch 16/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 775us/step - loss: 4948.7422 - mae: 46.5100 - val_loss: 3553.8594 - val_mae: 40.7318\n",
      "Epoch 17/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750us/step - loss: 4459.5454 - mae: 46.4533 - val_loss: 3629.4919 - val_mae: 41.1145\n",
      "Epoch 18/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step - loss: 4943.6860 - mae: 45.3109 - val_loss: 3792.9729 - val_mae: 42.2573\n",
      "Epoch 19/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870us/step - loss: 5398.8042 - mae: 46.5514 - val_loss: 3465.0029 - val_mae: 39.7786\n",
      "Epoch 20/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - loss: 5488.6606 - mae: 45.3725 - val_loss: 3703.9133 - val_mae: 41.5243\n",
      "Epoch 21/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758us/step - loss: 7147.6865 - mae: 46.8966 - val_loss: 3303.2080 - val_mae: 38.5273\n",
      "Epoch 22/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - loss: 5391.7500 - mae: 44.7100 - val_loss: 3234.5813 - val_mae: 37.9209\n",
      "Epoch 23/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - loss: 4966.5781 - mae: 44.8106 - val_loss: 3474.9521 - val_mae: 39.6997\n",
      "Epoch 24/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 871us/step - loss: 6099.8442 - mae: 45.3346 - val_loss: 3324.5740 - val_mae: 38.8116\n",
      "Epoch 25/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 5086.9546 - mae: 44.1573 - val_loss: 3172.0825 - val_mae: 37.5390\n",
      "Epoch 26/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 761us/step - loss: 4477.8950 - mae: 42.9324 - val_loss: 2951.7495 - val_mae: 35.6755\n",
      "Epoch 27/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - loss: 5076.9785 - mae: 42.5088 - val_loss: 3050.0469 - val_mae: 36.6933\n",
      "Epoch 28/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758us/step - loss: 4894.8896 - mae: 42.9092 - val_loss: 3108.6660 - val_mae: 37.1048\n",
      "Epoch 29/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 3971.9614 - mae: 41.4533 - val_loss: 2890.0022 - val_mae: 35.3501\n",
      "Epoch 30/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 948us/step - loss: 5832.5122 - mae: 42.6702 - val_loss: 3057.0376 - val_mae: 36.9125\n",
      "Epoch 31/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - loss: 4285.2578 - mae: 41.1003 - val_loss: 3236.1199 - val_mae: 38.3660\n",
      "Epoch 32/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758us/step - loss: 3644.8989 - mae: 40.5402 - val_loss: 2827.7593 - val_mae: 34.8774\n",
      "Epoch 33/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760us/step - loss: 4535.3745 - mae: 40.9316 - val_loss: 2917.8850 - val_mae: 35.6226\n",
      "Epoch 34/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 776us/step - loss: 4313.9336 - mae: 42.8338 - val_loss: 2745.8135 - val_mae: 34.0609\n",
      "Epoch 35/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - loss: 4556.9575 - mae: 40.9849 - val_loss: 3169.3130 - val_mae: 37.8532\n",
      "Epoch 36/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762us/step - loss: 4033.2061 - mae: 40.1142 - val_loss: 3224.8181 - val_mae: 38.1836\n",
      "Epoch 37/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 775us/step - loss: 5450.7539 - mae: 40.6162 - val_loss: 3182.7583 - val_mae: 37.8490\n",
      "Epoch 38/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762us/step - loss: 4510.6719 - mae: 40.6278 - val_loss: 2823.3333 - val_mae: 34.7315\n",
      "Epoch 39/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753us/step - loss: 4457.0732 - mae: 39.5842 - val_loss: 2641.0894 - val_mae: 33.0400\n",
      "Epoch 40/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755us/step - loss: 4872.8013 - mae: 39.8817 - val_loss: 3320.3188 - val_mae: 38.7912\n",
      "Epoch 41/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 784us/step - loss: 3910.0615 - mae: 41.1768 - val_loss: 2822.7542 - val_mae: 34.6417\n",
      "Epoch 42/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755us/step - loss: 5595.2578 - mae: 40.7222 - val_loss: 2868.8364 - val_mae: 35.0280\n",
      "Epoch 43/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 771us/step - loss: 4047.4543 - mae: 39.1774 - val_loss: 2811.3010 - val_mae: 34.6381\n",
      "Epoch 44/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752us/step - loss: 3308.9600 - mae: 37.6666 - val_loss: 2889.2063 - val_mae: 35.2717\n",
      "Epoch 45/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750us/step - loss: 3714.1667 - mae: 39.2263 - val_loss: 2800.4756 - val_mae: 34.4111\n",
      "Epoch 46/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 743us/step - loss: 3813.3418 - mae: 40.6594 - val_loss: 3048.3081 - val_mae: 36.5475\n",
      "Epoch 47/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834us/step - loss: 3831.3748 - mae: 40.2095 - val_loss: 3066.6753 - val_mae: 36.6538\n",
      "Epoch 48/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757us/step - loss: 4744.9277 - mae: 41.0577 - val_loss: 2857.3711 - val_mae: 34.9215\n",
      "Epoch 49/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 751us/step - loss: 4483.8027 - mae: 39.6938 - val_loss: 2886.4160 - val_mae: 35.1269\n",
      "Epoch 50/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 773us/step - loss: 3421.5894 - mae: 38.8516 - val_loss: 3077.2407 - val_mae: 36.8888\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "R² on test: 0.8181265075473554\n",
      "adjusted R² on test: 0.7350705471589336\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, Dense, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "# Transformation der Daten\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "X_test_preprocessed = preprocessor.transform(X_test)\n",
    "\n",
    "# Überprüfen der Dimensionen der transformierten Daten\n",
    "input_shape = X_train_preprocessed.shape[1]\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "  InputLayer(shape=(input_shape, )),\n",
    "  BatchNormalization(),\n",
    "  Dense(10, activation='relu'),\n",
    "  Dense(4, activation='relu'),\n",
    "  Dense(1)\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
    "\n",
    "# Training\n",
    "history = model.fit(\n",
    "    X_train_preprocessed,\n",
    "    y_train,\n",
    "    validation_data=(X_test_preprocessed, y_test),\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "y_pred = model.predict(X_test_preprocessed)\n",
    "print(\"R² on test:\", r2_score(y_test, y_pred))\n",
    "print(\"adjusted R² on test:\", adjr2(y_test, lr_y_pred, len(y), X.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modell auf Submission-Datensatz laufen lassen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Submission vorbereiten\n",
    "\n",
    "\n",
    "df_sub = pd.read_csv('../sample_submission.csv')\n",
    "\n",
    "# Angenommen, die Jahre sind 20xx:\n",
    "df_sub['id'] = df_sub['id'].astype('string')\n",
    "df_sub['Tag'] = df_sub['id'].str[0:2]\n",
    "df_sub['Monat'] = df_sub['id'].str[2:4]\n",
    "df_sub['Jahr'] = '20' + df_sub['id'].str[4:6]  # falls im Format YY z. B. 01 → 2001 oder 20xx\n",
    "\n",
    "df_sub['Warengruppe'] = df_sub['id'].str[6]  # letztes Zeichen\n",
    "df_sub['Warengruppe'] = df_sub['Warengruppe'].astype(int)\n",
    "\n",
    "# Ein Datum aus Tag, Monat, Jahr erzeugen:\n",
    "df_sub.rename(columns={'Jahr':'year', 'Monat':'month', 'Tag':'day'}, inplace=True)\n",
    "df_sub['Datum'] = pd.to_datetime(df_sub[['year','month','day']])\n",
    "df2['Datum'] = pd.to_datetime(df2['Datum'])\n",
    "df3['Datum'] = pd.to_datetime(df3['Datum'])\n",
    "df4['Datum'] = pd.to_datetime(df4['Datum'])\n",
    "df_sub = df_sub.merge(df4, on='Datum', how='left')\n",
    "df_sub = df_sub.merge(df3, on='Datum', how='left')\n",
    "df_sub = df_sub.merge(df2, on='Datum', how='left')\n",
    "\n",
    "df_sub['Wochentag'] = df_sub['Datum'].dt.weekday\n",
    "df_sub['Ist_Wochenende'] = df_sub['Wochentag'].isin([5,6])\n",
    "df_sub['Monat'] = df_sub['Datum'].dt.month\n",
    "df_sub['Monat_sin'] = np.sin(2 * np.pi * df_sub['Monat']/12)\n",
    "df_sub['Monat_cos'] = np.cos(2 * np.pi * df_sub['Monat']/12)\n",
    "\n",
    "# Check if all data types are correctly set for all variables\n",
    "print('### Initial datatypes')\n",
    "print(df_sub.dtypes)\n",
    "\n",
    "# Set the correct types for all variables\n",
    "\n",
    "df_sub['Wettercode'] = df_sub['Wettercode'].astype('category')\n",
    "df_sub['Warengruppe'] = df_sub['Warengruppe'].astype('category')\n",
    "\n",
    "\n",
    "# replace NaN with False for 'KielerWoche'\n",
    "df_sub['KielerWoche'] = df_sub['KielerWoche'].fillna(False)\n",
    "df_sub['KielerWoche'] = df_sub['KielerWoche'].astype('bool')\n",
    "print('### Corrected datatypes')\n",
    "print(df_sub.dtypes)\n",
    "\n",
    "\n",
    "# Datum in Datetime konvertieren\n",
    "df_sub['Datum'] = pd.to_datetime(df_sub['Datum'])\n",
    "\n",
    "# Basismerkmale\n",
    "df_sub['Jahr'] = df_sub['Datum'].dt.year\n",
    "df_sub['Monat'] = df_sub['Datum'].dt.month\n",
    "df_sub['Wochentag'] = df_sub['Datum'].dt.weekday\n",
    "df_sub['Kalenderwoche'] = df_sub['Datum'].dt.isocalendar().week\n",
    "df_sub['Tag_im_Jahr'] = df_sub['Datum'].dt.dayofyear\n",
    "df_sub['Tag_im_Jahr_sin'] = np.sin(2 * np.pi * df_sub['Tag_im_Jahr'] / 365)\n",
    "df_sub['Tag_im_Jahr_cos'] = np.cos(2 * np.pi * df_sub['Tag_im_Jahr'] / 365)\n",
    "df_sub['Ist_Wochenende'] = df_sub['Wochentag'].isin([5, 6]).astype(int)\n",
    "\n",
    "\n",
    "# Zyklische Merkmale\n",
    "df_sub['Monat_sin'] = np.sin(2 * np.pi * df_sub['Monat'] / 12)\n",
    "df_sub['Monat_cos'] = np.cos(2 * np.pi * df_sub['Monat'] / 12)\n",
    "df_sub['Wochentag_sin'] = np.sin(2 * np.pi * df_sub['Wochentag'] / 7)\n",
    "df_sub['Wochentag_cos'] = np.cos(2 * np.pi * df_sub['Wochentag'] / 7)\n",
    "\n",
    "\n",
    "# Beispiel für Mittelwert-Imputation\n",
    "df_sub['Temperatur'].fillna(df_sub['Temperatur'].mean(), inplace=True)\n",
    "df_sub['Bewoelkung'].fillna(df_sub['Bewoelkung'].mean(), inplace=True)\n",
    "df_sub['Windgeschwindigkeit'].fillna(df_sub['Windgeschwindigkeit'].mean(), inplace=True)\n",
    "\n",
    "df_sub['Wettercode'] = df_sub['Wettercode'].cat.add_categories(['Unbekannt'])\n",
    "df_sub['Wettercode'] = df_sub['Wettercode'].fillna('Unbekannt')\n",
    "\n",
    "\n",
    "# Sicherstellen, dass 'Datum' als datetime konvertiert ist\n",
    "df['Datum'] = pd.to_datetime(df['Datum'])\n",
    "\n",
    "\n",
    "\n",
    "# 5. Vorhersagen treffen und evaluieren\n",
    "y_pred_sub = pipeline.predict(df_sub)\n",
    "y_pred_sub_best = grid_search.predict(df_sub)\n",
    "\n",
    "df_sub['Umsatz'] = y_pred_sub_best\n",
    "\n",
    "# Erstellen der finalen Submission:\n",
    "df_sub[['id','Umsatz']].to_csv('../submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
